# with open("/home/shivank2/gokhale_user/shivanand/mammoth/data/results/class-il/seq-cifar100/icarl/logs.pyd", "r", encoding="utf-8", errors="ignore") as f:
#     logs = f.read()
# # logs = dict(eval(logs))
# # print(logs.keys())

# print(logs[0:5000])  # Print the first 1000 characters to check the format
# print(len(logs))
import numpy as np
icarl_og = {'accmean_task1': np.float64(86.4), 'accmean_task2': np.float64(75.05), 'accmean_task3': np.float64(70.86666666666666), 'accmean_task4': np.float64(65.65), 'accmean_task5': np.float64(62.18000000000001), 'accmean_task6': np.float64(59.24999999999999), 'accmean_task7': np.float64(56.57142857142857), 'accmean_task8': np.float64(53.487500000000004), 'accmean_task9': np.float64(51.93333333333334), 'accmean_task10': np.float64(49.06), 'accuracy_1_task1': 86.4, 'accuracy_1_task2': 80.7, 'accuracy_2_task2': 69.39999999999999, 'accuracy_1_task3': 75.9, 'accuracy_2_task3': 66.60000000000001, 'accuracy_3_task3': 70.1, 'accuracy_1_task4': 69.5, 'accuracy_2_task4': 61.4, 'accuracy_3_task4': 67.5, 'accuracy_4_task4': 64.2, 'accuracy_1_task5': 64.60000000000001, 'accuracy_2_task5': 56.8, 'accuracy_3_task5': 64.4, 'accuracy_4_task5': 59.8, 'accuracy_5_task5': 65.3, 'accuracy_1_task6': 60.199999999999996, 'accuracy_2_task6': 53.300000000000004, 'accuracy_3_task6': 60.199999999999996, 'accuracy_4_task6': 57.49999999999999, 'accuracy_5_task6': 60.4, 'accuracy_6_task6': 63.9, 'accuracy_1_task7': 56.2, 'accuracy_2_task7': 49.7, 'accuracy_3_task7': 55.50000000000001, 'accuracy_4_task7': 54.50000000000001, 'accuracy_5_task7': 55.50000000000001, 'accuracy_6_task7': 60.4, 'accuracy_7_task7': 64.2, 'accuracy_1_task8': 52.7, 'accuracy_2_task8': 46.6, 'accuracy_3_task8': 52.400000000000006, 'accuracy_4_task8': 50.7, 'accuracy_5_task8': 53.300000000000004, 'accuracy_6_task8': 56.3, 'accuracy_7_task8': 57.4, 'accuracy_8_task8': 58.5, 'accuracy_1_task9': 50.3, 'accuracy_2_task9': 45.2, 'accuracy_3_task9': 51.800000000000004, 'accuracy_4_task9': 48.1, 'accuracy_5_task9': 50.2, 'accuracy_6_task9': 53.300000000000004, 'accuracy_7_task9': 53.900000000000006, 'accuracy_8_task9': 53.400000000000006, 'accuracy_9_task9': 61.199999999999996, 'accuracy_1_task10': 46.7, 'accuracy_2_task10': 44.2, 'accuracy_3_task10': 49.9, 'accuracy_4_task10': 41.699999999999996, 'accuracy_5_task10': 47.199999999999996, 'accuracy_6_task10': 50.6, 'accuracy_7_task10': 48.699999999999996, 'accuracy_8_task10': 49.6, 'accuracy_9_task10': 58.4, 'accuracy_10_task10': 53.6}
icarl_ours = {'accmean_task1': np.float64(85.6), 'accmean_task2': np.float64(77.25), 'accmean_task3': np.float64(71.43333333333334), 'accmean_task4': np.float64(66.225), 'accmean_task5': np.float64(63.3), 'accmean_task6': np.float64(59.98333333333334), 'accmean_task7': np.float64(57.74285714285714), 'accmean_task8': np.float64(54.4), 'accmean_task9': np.float64(52.06666666666666), 'accmean_task10': np.float64(49.73), 'accuracy_1_task1': 85.6, 'accuracy_1_task2': 81.39999999999999, 'accuracy_2_task2': 73.1, 'accuracy_1_task3': 74.4, 'accuracy_2_task3': 67.60000000000001, 'accuracy_3_task3': 72.3, 'accuracy_1_task4': 68.89999999999999, 'accuracy_2_task4': 62.2, 'accuracy_3_task4': 68.4, 'accuracy_4_task4': 65.4, 'accuracy_1_task5': 65.9, 'accuracy_2_task5': 58.3, 'accuracy_3_task5': 62.5, 'accuracy_4_task5': 61.4, 'accuracy_5_task5': 68.4, 'accuracy_1_task6': 61.8, 'accuracy_2_task6': 53.900000000000006, 'accuracy_3_task6': 62.1, 'accuracy_4_task6': 57.3, 'accuracy_5_task6': 58.599999999999994, 'accuracy_6_task6': 66.2, 'accuracy_1_task7': 57.49999999999999, 'accuracy_2_task7': 52.7, 'accuracy_3_task7': 57.8, 'accuracy_4_task7': 54.900000000000006, 'accuracy_5_task7': 56.8, 'accuracy_6_task7': 59.8, 'accuracy_7_task7': 64.7, 'accuracy_1_task8': 55.1, 'accuracy_2_task8': 49.0, 'accuracy_3_task8': 55.60000000000001, 'accuracy_4_task8': 51.9, 'accuracy_5_task8': 52.900000000000006, 'accuracy_6_task8': 56.699999999999996, 'accuracy_7_task8': 55.800000000000004, 'accuracy_8_task8': 58.199999999999996, 'accuracy_1_task9': 52.2, 'accuracy_2_task9': 46.7, 'accuracy_3_task9': 53.7, 'accuracy_4_task9': 48.8, 'accuracy_5_task9': 48.5, 'accuracy_6_task9': 54.1, 'accuracy_7_task9': 51.9, 'accuracy_8_task9': 51.9, 'accuracy_9_task9': 60.8, 'accuracy_1_task10': 49.9, 'accuracy_2_task10': 46.0, 'accuracy_3_task10': 51.5, 'accuracy_4_task10': 43.0, 'accuracy_5_task10': 46.5, 'accuracy_6_task10': 50.7, 'accuracy_7_task10': 49.0, 'accuracy_8_task10': 48.699999999999996, 'accuracy_9_task10': 55.800000000000004, 'accuracy_10_task10': 56.2,}
# print(og)
coda_og={'accmean_task1': np.float64(99.2), 'accmean_task2': np.float64(94.8), 'accmean_task3': np.float64(93.33333333333333), 'accmean_task4': np.float64(91.825), 'accmean_task5': np.float64(90.72), 'accmean_task6': np.float64(88.5), 'accmean_task7': np.float64(88.15714285714286), 'accmean_task8': np.float64(87.475), 'accmean_task9': np.float64(87.6), 'accmean_task10': np.float64(86.79), 'accuracy_1_task1': 99.2, 'accuracy_1_task2': 93.89999999999999, 'accuracy_2_task2': 95.7, 'accuracy_1_task3': 90.5, 'accuracy_2_task3': 93.89999999999999, 'accuracy_3_task3': 95.6, 'accuracy_1_task4': 90.10000000000001, 'accuracy_2_task4': 91.0, 'accuracy_3_task4': 95.7, 'accuracy_4_task4': 90.5, 'accuracy_1_task5': 89.3, 'accuracy_2_task5': 87.4, 'accuracy_3_task5': 93.8, 'accuracy_4_task5': 90.10000000000001, 'accuracy_5_task5': 93.0, 'accuracy_1_task6': 88.1, 'accuracy_2_task6': 85.8, 'accuracy_3_task6': 93.10000000000001, 'accuracy_4_task6': 89.4, 'accuracy_5_task6': 93.10000000000001, 'accuracy_6_task6': 81.5, 'accuracy_1_task7': 87.9, 'accuracy_2_task7': 85.0, 'accuracy_3_task7': 91.9, 'accuracy_4_task7': 88.5, 'accuracy_5_task7': 91.7, 'accuracy_6_task7': 80.60000000000001, 'accuracy_7_task7': 91.5, 'accuracy_1_task8': 87.1, 'accuracy_2_task8': 84.6, 'accuracy_3_task8': 90.10000000000001, 'accuracy_4_task8': 88.3, 'accuracy_5_task8': 92.9, 'accuracy_6_task8': 79.60000000000001, 'accuracy_7_task8': 90.4, 'accuracy_8_task8': 86.8, 'accuracy_1_task9': 86.8, 'accuracy_2_task9': 83.8, 'accuracy_3_task9': 90.3, 'accuracy_4_task9': 88.5, 'accuracy_5_task9': 92.2, 'accuracy_6_task9': 78.4, 'accuracy_7_task9': 89.3, 'accuracy_8_task9': 86.6, 'accuracy_9_task9': 92.5, 'accuracy_1_task10': 86.4, 'accuracy_2_task10': 82.89999999999999, 'accuracy_3_task10': 89.9, 'accuracy_4_task10': 85.9, 'accuracy_5_task10': 90.4, 'accuracy_6_task10': 78.5, 'accuracy_7_task10': 88.4, 'accuracy_8_task10': 83.6, 'accuracy_9_task10': 91.7, 'accuracy_10_task10': 90.2}
coda_ours={'accmean_task1': np.float64(99.1), 'accmean_task2': np.float64(95.64999999999999), 'accmean_task3': np.float64(94.03333333333332), 'accmean_task4': np.float64(92.175), 'accmean_task5': np.float64(91.12), 'accmean_task6': np.float64(88.91666666666669), 'accmean_task7': np.float64(88.08571428571427), 'accmean_task8': np.float64(87.57499999999999), 'accmean_task9': np.float64(87.6888888888889), 'accmean_task10': np.float64(86.55999999999999), 'accuracy_1_task1': 99.1, 'accuracy_1_task2': 96.1, 'accuracy_2_task2': 95.19999999999999, 'accuracy_1_task3': 93.89999999999999, 'accuracy_2_task3': 93.8, 'accuracy_3_task3': 94.39999999999999, 'accuracy_1_task4': 91.7, 'accuracy_2_task4': 88.9, 'accuracy_3_task4': 94.19999999999999, 'accuracy_4_task4': 93.89999999999999, 'accuracy_1_task5': 89.9, 'accuracy_2_task5': 87.7, 'accuracy_3_task5': 92.80000000000001, 'accuracy_4_task5': 92.30000000000001, 'accuracy_5_task5': 92.9, 'accuracy_1_task6': 87.4, 'accuracy_2_task6': 86.4, 'accuracy_3_task6': 91.9, 'accuracy_4_task6': 91.3, 'accuracy_5_task6': 92.60000000000001, 'accuracy_6_task6': 83.89999999999999, 'accuracy_1_task7': 87.2, 'accuracy_2_task7': 85.3, 'accuracy_3_task7': 90.9, 'accuracy_4_task7': 90.7, 'accuracy_5_task7': 92.0, 'accuracy_6_task7': 82.5, 'accuracy_7_task7': 88.0, 'accuracy_1_task8': 87.0, 'accuracy_2_task8': 85.39999999999999, 'accuracy_3_task8': 90.8, 'accuracy_4_task8': 90.60000000000001, 'accuracy_5_task8': 92.2, 'accuracy_6_task8': 81.39999999999999, 'accuracy_7_task8': 86.6, 'accuracy_8_task8': 86.6, 'accuracy_1_task9': 86.6, 'accuracy_2_task9': 84.89999999999999, 'accuracy_3_task9': 90.7, 'accuracy_4_task9': 90.5, 'accuracy_5_task9': 91.60000000000001, 'accuracy_6_task9': 80.5, 'accuracy_7_task9': 85.5, 'accuracy_8_task9': 85.6, 'accuracy_9_task9': 93.30000000000001, 'accuracy_1_task10': 86.1, 'accuracy_2_task10': 84.3, 'accuracy_3_task10': 90.60000000000001, 'accuracy_4_task10': 89.1, 'accuracy_5_task10': 90.3, 'accuracy_6_task10': 78.9, 'accuracy_7_task10': 83.8, 'accuracy_8_task10': 82.5, 'accuracy_9_task10': 92.4, 'accuracy_10_task10': 87.6}

def metric1(og, ours):
    ranks=np.zeros(10)
    metric = 0
    avg1=0
    avg2=0
    for i in range(10):
        # print(i)
        avg1+=ours[f'accmean_task{i+1}']
        avg2+=og[f'accmean_task{i+1}']
        ranks[i]= 1 if (ours[f'accmean_task{i+1}'] - og[f'accmean_task{i+1}']) >0 else 0
    metric= ranks.mean()
    print(avg1/10, avg2/10)
    return metric
# print()
print("Icarl:" ,metric1(icarl_og, icarl_ours))
print("coda-prompt",metric1(coda_og, coda_ours))
# def metric2(og, ours):  
#     metric = 0
#     for i in range(1, 11):
#         metric += abs(og[f'accuracy_{i}_task{i}'] - ours[f'accuracy_{i}_task{i}'])
#     return metric
